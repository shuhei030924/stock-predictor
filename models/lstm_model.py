"""
LSTM ãƒ¢ãƒ‡ãƒ« - GPUå¯¾å¿œã®æ™‚ç³»åˆ—äºˆæ¸¬
================================
PyTorchã‚’ä½¿ç”¨ã—ãŸLSTMãƒ¢ãƒ‡ãƒ«ã§GPUé«˜é€Ÿäºˆæ¸¬ã‚’å®Ÿç¾
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from typing import Tuple, Optional


# ãƒ‡ãƒã‚¤ã‚¹è¨­å®šï¼ˆGPUåˆ©ç”¨å¯èƒ½ãªã‚‰GPUã€ãªã‘ã‚Œã°CPUï¼‰
def get_device():
    """åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒã‚¤ã‚¹ã‚’å–å¾—"""
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"ğŸš€ GPUä½¿ç”¨: {torch.cuda.get_device_name(0)}")
    else:
        device = torch.device("cpu")
        print("ğŸ’» CPUä½¿ç”¨")
    return device


class LSTMModel(nn.Module):
    """LSTMæ™‚ç³»åˆ—äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«"""
    
    def __init__(self, input_size: int = 1, hidden_size: int = 64, 
                 num_layers: int = 2, output_size: int = 1, dropout: float = 0.2):
        super(LSTMModel, self).__init__()
        
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0
        )
        
        self.fc = nn.Sequential(
            nn.Linear(hidden_size, 32),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(32, output_size)
        )
    
    def forward(self, x):
        # LSTMå±¤
        lstm_out, _ = self.lstm(x)
        # æœ€å¾Œã®æ™‚ç‚¹ã®å‡ºåŠ›ã‚’ä½¿ç”¨
        out = self.fc(lstm_out[:, -1, :])
        return out


class StockLSTMPredictor:
    """æ ªä¾¡äºˆæ¸¬ç”¨LSTMãƒ©ãƒƒãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, sequence_length: int = 30, hidden_size: int = 64,
                 num_layers: int = 2, learning_rate: float = 0.001):
        self.sequence_length = sequence_length
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.learning_rate = learning_rate
        
        self.device = get_device()
        self.model = None
        self.scaler = MinMaxScaler()
        self.is_trained = False
    
    def prepare_data(self, data: np.ndarray) -> Tuple[torch.Tensor, torch.Tensor]:
        """ãƒ‡ãƒ¼ã‚¿ã‚’LSTMç”¨ã«æ•´å½¢"""
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        scaled_data = self.scaler.fit_transform(data.reshape(-1, 1))
        
        X, y = [], []
        for i in range(self.sequence_length, len(scaled_data)):
            X.append(scaled_data[i - self.sequence_length:i, 0])
            y.append(scaled_data[i, 0])
        
        X = np.array(X)
        y = np.array(y)
        
        # PyTorchãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
        X = torch.FloatTensor(X).unsqueeze(-1)  # (batch, seq_len, 1)
        y = torch.FloatTensor(y).unsqueeze(-1)  # (batch, 1)
        
        return X.to(self.device), y.to(self.device)
    
    def train(self, data: np.ndarray, epochs: int = 100, 
              batch_size: int = 32, verbose: bool = True) -> list:
        """ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´"""
        X, y = self.prepare_data(data)
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        self.model = LSTMModel(
            input_size=1,
            hidden_size=self.hidden_size,
            num_layers=self.num_layers
        ).to(self.device)
        
        criterion = nn.MSELoss()
        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='min', factor=0.5, patience=10
        )
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        dataset = torch.utils.data.TensorDataset(X, y)
        dataloader = torch.utils.data.DataLoader(
            dataset, batch_size=batch_size, shuffle=True
        )
        
        losses = []
        self.model.train()
        
        for epoch in range(epochs):
            epoch_loss = 0
            for batch_X, batch_y in dataloader:
                optimizer.zero_grad()
                outputs = self.model(batch_X)
                loss = criterion(outputs, batch_y)
                loss.backward()
                optimizer.step()
                epoch_loss += loss.item()
            
            avg_loss = epoch_loss / len(dataloader)
            losses.append(avg_loss)
            scheduler.step(avg_loss)
            
            if verbose and (epoch + 1) % 20 == 0:
                print(f"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.6f}")
        
        self.is_trained = True
        return losses
    
    def predict(self, data: np.ndarray, forecast_days: int = 30) -> np.ndarray:
        """å°†æ¥ã®æ ªä¾¡ã‚’äºˆæ¸¬"""
        if not self.is_trained:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«train()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        
        self.model.eval()
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        scaled_data = self.scaler.transform(data.reshape(-1, 1))
        
        predictions = []
        current_seq = scaled_data[-self.sequence_length:].flatten().tolist()
        
        with torch.no_grad():
            for _ in range(forecast_days):
                # å…¥åŠ›ã‚’æº–å‚™
                seq_tensor = torch.FloatTensor(current_seq[-self.sequence_length:])
                seq_tensor = seq_tensor.unsqueeze(0).unsqueeze(-1).to(self.device)
                
                # äºˆæ¸¬
                pred = self.model(seq_tensor)
                pred_value = pred.cpu().numpy()[0, 0]
                
                predictions.append(pred_value)
                current_seq.append(pred_value)
        
        # ã‚¹ã‚±ãƒ¼ãƒ«ã‚’æˆ»ã™
        predictions = np.array(predictions).reshape(-1, 1)
        predictions = self.scaler.inverse_transform(predictions)
        
        return predictions.flatten()
    
    def backtest(self, data: np.ndarray, test_days: int = 30, 
                 train_epochs: int = 50) -> pd.DataFrame:
        """ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        results = []
        
        for i in range(test_days, 0, -1):
            train_data = data[:-i]
            actual = data[-i]
            
            if len(train_data) < self.sequence_length + 50:
                continue
            
            try:
                # è¨“ç·´ï¼ˆå°‘ãªã„ã‚¨ãƒãƒƒã‚¯ã§é«˜é€ŸåŒ–ï¼‰
                self.train(train_data, epochs=train_epochs, verbose=False)
                
                # 1æ—¥å…ˆã‚’äºˆæ¸¬
                pred = self.predict(train_data, forecast_days=1)[0]
                
                results.append({
                    'Index': len(data) - i,
                    'Actual': actual,
                    'Predicted': pred,
                    'Error': actual - pred,
                    'Error_Pct': (actual - pred) / actual * 100
                })
            except Exception as e:
                continue
        
        return pd.DataFrame(results)
    
    def save_model(self, path: str):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
        if self.model is not None:
            torch.save({
                'model_state_dict': self.model.state_dict(),
                'scaler': self.scaler,
                'sequence_length': self.sequence_length,
                'hidden_size': self.hidden_size,
                'num_layers': self.num_layers
            }, path)
            print(f"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {path}")
    
    def load_model(self, path: str):
        """ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        checkpoint = torch.load(path, map_location=self.device)
        
        self.sequence_length = checkpoint['sequence_length']
        self.hidden_size = checkpoint['hidden_size']
        self.num_layers = checkpoint['num_layers']
        self.scaler = checkpoint['scaler']
        
        self.model = LSTMModel(
            input_size=1,
            hidden_size=self.hidden_size,
            num_layers=self.num_layers
        ).to(self.device)
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.is_trained = True
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {path}")


def check_gpu_availability():
    """GPUæƒ…å ±ã‚’è¡¨ç¤º"""
    print("=" * 50)
    print("GPU Information")
    print("=" * 50)
    
    if torch.cuda.is_available():
        print(f"âœ… CUDA Available: True")
        print(f"   Device Name: {torch.cuda.get_device_name(0)}")
        print(f"   CUDA Version: {torch.version.cuda}")
        print(f"   Device Count: {torch.cuda.device_count()}")
        
        # ãƒ¡ãƒ¢ãƒªæƒ…å ±
        total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"   Total Memory: {total_memory:.2f} GB")
    else:
        print("âŒ CUDA Available: False")
        print("   Using CPU instead")
    
    print("=" * 50)


if __name__ == "__main__":
    # GPUç¢ºèª
    check_gpu_availability()
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
    np.random.seed(42)
    days = 500
    returns = np.random.normal(0.0005, 0.02, days)
    prices = 100 * np.exp(np.cumsum(returns))
    
    # äºˆæ¸¬ãƒ†ã‚¹ãƒˆ
    predictor = StockLSTMPredictor(sequence_length=30, hidden_size=64)
    
    print("\nè¨“ç·´é–‹å§‹...")
    losses = predictor.train(prices, epochs=50, verbose=True)
    
    print("\näºˆæ¸¬å®Ÿè¡Œ...")
    predictions = predictor.predict(prices, forecast_days=10)
    print(f"10æ—¥é–“ã®äºˆæ¸¬: {predictions}")
