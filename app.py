"""
æ ªä¾¡äºˆæ¸¬ãƒ„ãƒ¼ãƒ« - Streamlit Web ã‚¢ãƒ—ãƒªç‰ˆ
=====================================
ãƒ–ãƒ©ã‚¦ã‚¶ã§å‹•ä½œã™ã‚‹ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªæ ªä¾¡äºˆæ¸¬ãƒ„ãƒ¼ãƒ«

èµ·å‹•æ–¹æ³•:
    streamlit run app.py
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆæœ€åˆã«å®Ÿè¡Œï¼‰
st.set_page_config(
    page_title="ğŸ“ˆ æ ªä¾¡äºˆæ¸¬ãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ“ˆ",
    layout="wide"
)

# é‡ã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆä½¿ç”¨æ™‚ã«ã®ã¿èª­ã¿è¾¼ã¿ï¼‰
@st.cache_resource
def load_plotly():
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    return go, make_subplots

@st.cache_resource
def load_yfinance():
    try:
        import yfinance as yf
        return yf, True
    except ImportError:
        return None, False

@st.cache_resource
def load_statsmodels():
    from statsmodels.tsa.arima.model import ARIMA
    return ARIMA

@st.cache_resource
def load_sklearn():
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.preprocessing import StandardScaler
    from sklearn.model_selection import train_test_split
    return RandomForestRegressor, StandardScaler, train_test_split

@st.cache_resource
def load_pytorch():
    try:
        import torch
        from models.lstm_model import StockLSTMPredictor, get_device
        return torch, StockLSTMPredictor, get_device, True
    except ImportError:
        return None, None, None, False

@st.cache_resource
def load_lightgbm():
    try:
        from models.lightgbm_model import StockLightGBMPredictor, LIGHTGBM_AVAILABLE
        return StockLightGBMPredictor, LIGHTGBM_AVAILABLE
    except ImportError:
        return None, False

@st.cache_resource
def load_garch():
    try:
        from models.garch_model import StockGARCHPredictor, ARCH_AVAILABLE
        return StockGARCHPredictor, ARCH_AVAILABLE
    except ImportError:
        return None, False

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åˆ©ç”¨å¯èƒ½æ€§ã‚’è»½é‡ãƒã‚§ãƒƒã‚¯ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ç”¨ï¼‰
@st.cache_resource
def check_lightgbm_available():
    try:
        import importlib.util
        return importlib.util.find_spec("lightgbm") is not None
    except:
        return False

@st.cache_resource
def check_garch_available():
    try:
        import importlib.util
        return importlib.util.find_spec("arch") is not None
    except:
        return False

@st.cache_resource
def check_pytorch_available():
    try:
        import importlib.util
        return importlib.util.find_spec("torch") is not None
    except:
        return False

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
.big-font {
    font-size: 24px !important;
    font-weight: bold;
}
.signal-buy {
    background-color: #d4edda;
    padding: 10px;
    border-radius: 5px;
    border-left: 5px solid #28a745;
}
.signal-sell {
    background-color: #f8d7da;
    padding: 10px;
    border-radius: 5px;
    border-left: 5px solid #dc3545;
}
.signal-neutral {
    background-color: #fff3cd;
    padding: 10px;
    border-radius: 5px;
    border-left: 5px solid #ffc107;
}
</style>
""", unsafe_allow_html=True)


def fetch_stock_data_from_api(ticker: str, period: str) -> pd.DataFrame:
    """æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’APIã‹ã‚‰å–å¾—ï¼ˆå†…éƒ¨ç”¨ï¼‰"""
    yf, yf_available = load_yfinance()
    if yf_available:
        try:
            import ssl
            ssl._create_default_https_context = ssl._create_unverified_context
            stock = yf.Ticker(ticker)
            data = stock.history(period=period)
            if len(data) > 0:
                return data
        except:
            pass
    
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆAPIãŒä½¿ãˆãªã„å ´åˆï¼‰
    np.random.seed(hash(ticker) % 100)
    days = 500
    dates = pd.date_range(end=datetime.now(), periods=days, freq='B')
    returns = np.random.normal(0.0005, 0.02, days)
    price = 100 * np.exp(np.cumsum(returns))
    
    return pd.DataFrame({
        'Open': price * (1 + np.random.uniform(-0.01, 0.01, days)),
        'High': price * (1 + np.random.uniform(0, 0.02, days)),
        'Low': price * (1 - np.random.uniform(0, 0.02, days)),
        'Close': price,
        'Volume': np.random.randint(1000000, 10000000, days)
    }, index=dates)


def fetch_stock_data(ticker: str, period: str, use_smart_cache: bool = True):
    """
    æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚¹ãƒãƒ¼ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰
    
    Returns:
        tuple: (DataFrame, source) - sourceã¯ "cache", "api", "stale_cache" ã®ã„ãšã‚Œã‹
    """
    # DBãŒä½¿ãˆãªã„å ´åˆã¯ç›´æ¥API
    if not db_available or not use_smart_cache:
        return fetch_stock_data_from_api(ticker, period), "api"
    
    # ã‚¹ãƒãƒ¼ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨
    try:
        from services import smart_fetch_stock_data
        return smart_fetch_stock_data(
            ticker=ticker,
            period=period,
            db_manager=db,
            api_fetch_func=fetch_stock_data_from_api,
            cache_max_age_hours=6  # 6æ™‚é–“ä»¥å†…ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯å†åˆ©ç”¨
        )
    except ImportError:
        return fetch_stock_data_from_api(ticker, period), "api"


def add_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã‚’è¿½åŠ """
    df = df.copy()
    
    # ç§»å‹•å¹³å‡
    df['SMA_5'] = df['Close'].rolling(window=5).mean()
    df['SMA_20'] = df['Close'].rolling(window=20).mean()
    df['SMA_50'] = df['Close'].rolling(window=50).mean()
    
    # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
    df['BB_middle'] = df['Close'].rolling(window=20).mean()
    df['BB_std'] = df['Close'].rolling(window=20).std()
    df['BB_upper'] = df['BB_middle'] + 2 * df['BB_std']
    df['BB_lower'] = df['BB_middle'] - 2 * df['BB_std']
    
    # RSI
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))
    
    # MACD
    exp1 = df['Close'].ewm(span=12, adjust=False).mean()
    exp2 = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = exp1 - exp2
    df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
    
    # ãã®ä»–
    df['Return'] = df['Close'].pct_change()
    df['Return_5d'] = df['Close'].pct_change(5)
    df['Volume_SMA'] = df['Volume'].rolling(window=20).mean()
    df['Volume_ratio'] = df['Volume'] / df['Volume_SMA']
    
    return df.dropna()


def predict_arima(data: pd.DataFrame, forecast_days: int):
    """ARIMAäºˆæ¸¬ï¼ˆãƒªã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ï¼‰"""
    ARIMA = load_statsmodels()
    
    # ãƒªã‚¿ãƒ¼ãƒ³ã‚’äºˆæ¸¬ï¼ˆä¾¡æ ¼ç›´æ¥ã‚ˆã‚Šå®‰å®šï¼‰
    returns = data['Close'].pct_change().dropna()
    
    best_aic = float('inf')
    best_order = (1, 1, 1)
    
    for p in range(3):
        for q in range(3):
            try:
                model = ARIMA(returns, order=(p, 1, q))
                result = model.fit()
                if result.aic < best_aic:
                    best_aic = result.aic
                    best_order = (p, 1, q)
            except:
                continue
    
    model = ARIMA(returns, order=best_order)
    result = model.fit()
    forecast = result.get_forecast(steps=forecast_days)
    
    # ãƒªã‚¿ãƒ¼ãƒ³äºˆæ¸¬ã‚’ä¾¡æ ¼ã«å¤‰æ›
    predicted_returns = forecast.predicted_mean.values
    last_price = data['Close'].iloc[-1]
    
    # ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ã§ä¾¡æ ¼ã‚’è¨ˆç®—
    predicted_prices = [last_price]
    for ret in predicted_returns:
        # ãƒªã‚¿ãƒ¼ãƒ³ã‚’åˆ¶é™ï¼ˆæ¥µç«¯ãªäºˆæ¸¬ã‚’é˜²ãï¼‰
        ret = np.clip(ret, -0.05, 0.05)  # æ—¥æ¬¡Â±5%ä»¥å†…
        predicted_prices.append(predicted_prices[-1] * (1 + ret))
    
    predicted_prices = np.array(predicted_prices[1:])
    
    # ä¿¡é ¼åŒºé–“ã‚‚èª¿æ•´ï¼ˆã‚ˆã‚Šå³ã—ãåˆ¶é™ï¼‰
    ci = forecast.conf_int()
    ci_lower = [last_price]
    ci_upper = [last_price]
    for i in range(len(ci)):
        # æ—¥æ¬¡Â±3%ã«å³ã—ãåˆ¶é™
        ret_lower = np.clip(ci.iloc[i, 0], -0.03, 0.03)
        ret_upper = np.clip(ci.iloc[i, 1], -0.03, 0.03)
        ci_lower.append(ci_lower[-1] * (1 + ret_lower))
        ci_upper.append(ci_upper[-1] * (1 + ret_upper))
    
    ci_df = pd.DataFrame({
        'lower': ci_lower[1:],
        'upper': ci_upper[1:]
    })
    
    # ä¿¡é ¼åŒºé–“ãŒç¾åœ¨ä¾¡æ ¼ã®Â±30%ã‚’è¶…ãˆãŸã‚‰Noneã‚’è¿”ã™ï¼ˆãƒãƒ£ãƒ¼ãƒˆã«è¡¨ç¤ºã—ãªã„ï¼‰
    if ci_df['upper'].max() > last_price * 1.3 or ci_df['lower'].min() < last_price * 0.7:
        ci_df = None
    
    return pd.Series(predicted_prices), ci_df, best_order


def predict_ml(data: pd.DataFrame, forecast_days: int):
    """æ©Ÿæ¢°å­¦ç¿’äºˆæ¸¬ï¼ˆãƒªã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ + ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰"""
    RandomForestRegressor, StandardScaler, train_test_split = load_sklearn()
    from sklearn.ensemble import GradientBoostingRegressor
    
    df_ml = data.copy()
    
    # ãƒªã‚¿ãƒ¼ãƒ³ã‚’äºˆæ¸¬ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«
    df_ml['Target_Return'] = df_ml['Close'].pct_change().shift(-1)
    
    # ã‚ˆã‚Šå¤šãã®ç‰¹å¾´é‡
    for i in range(1, 11):
        df_ml[f'Return_lag{i}'] = df_ml['Close'].pct_change().shift(i)
    
    df_ml['Volatility_10'] = df_ml['Close'].pct_change().rolling(10).std()
    df_ml['Volatility_20'] = df_ml['Close'].pct_change().rolling(20).std()
    df_ml['Price_SMA5_ratio'] = df_ml['Close'] / df_ml['SMA_5']
    df_ml['Price_SMA20_ratio'] = df_ml['Close'] / df_ml['SMA_20']
    
    df_ml = df_ml.dropna()
    
    features = ['RSI', 'MACD', 'Volume_ratio', 'Volatility_10', 'Volatility_20',
                'Price_SMA5_ratio', 'Price_SMA20_ratio'] + \
               [f'Return_lag{i}' for i in range(1, 11)]
    
    X = df_ml[features].values[:-1]  # æœ€å¾Œã®è¡Œã¯ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãŒNaN
    y = df_ml['Target_Return'].values[:-1]
    
    split_idx = int(len(X) * 0.8)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«: RF + GradientBoosting
    rf_model = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)
    gb_model = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)
    
    rf_model.fit(X_train_scaled, y_train)
    gb_model.fit(X_train_scaled, y_train)
    
    # ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢ï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰
    rf_pred = rf_model.predict(X_test_scaled)
    gb_pred = gb_model.predict(X_test_scaled)
    ensemble_pred = (rf_pred + gb_pred) / 2
    
    from sklearn.metrics import r2_score
    score = r2_score(y_test, ensemble_pred)
    
    # äºˆæ¸¬
    last_price = data['Close'].iloc[-1]
    predictions = [last_price]
    
    # æœ€æ–°ã®ç‰¹å¾´é‡ã‚’å–å¾—
    current_features = df_ml[features].iloc[-1:].values
    
    for _ in range(forecast_days):
        current_scaled = scaler.transform(current_features)
        rf_ret = rf_model.predict(current_scaled)[0]
        gb_ret = gb_model.predict(current_scaled)[0]
        predicted_return = (rf_ret + gb_ret) / 2
        
        # ãƒªã‚¿ãƒ¼ãƒ³ã‚’åˆ¶é™ï¼ˆæ¥µç«¯ãªäºˆæ¸¬ã‚’é˜²ãï¼‰
        predicted_return = np.clip(predicted_return, -0.03, 0.03)  # æ—¥æ¬¡Â±3%ä»¥å†…
        
        next_price = predictions[-1] * (1 + predicted_return)
        predictions.append(next_price)
        
        # ç‰¹å¾´é‡ã‚’æ›´æ–°ï¼ˆãƒªã‚¿ãƒ¼ãƒ³ãƒ©ã‚°ã‚’ã‚·ãƒ•ãƒˆï¼‰
        current_features = np.roll(current_features, 1, axis=1)
        current_features[0, 6] = predicted_return  # Return_lag1ã‚’æ›´æ–°
    
    return np.array(predictions[1:]), score


def get_signals(data: pd.DataFrame) -> list:
    """å£²è²·ã‚·ã‚°ãƒŠãƒ«ã‚’å–å¾—"""
    latest = data.iloc[-1]
    signals = []
    
    # RSI
    if latest['RSI'] < 30:
        signals.append(('RSI', 'è²·ã„', f"RSI={latest['RSI']:.1f} (å£²ã‚‰ã‚Œã™ã)", 'buy'))
    elif latest['RSI'] > 70:
        signals.append(('RSI', 'å£²ã‚Š', f"RSI={latest['RSI']:.1f} (è²·ã‚ã‚Œã™ã)", 'sell'))
    else:
        signals.append(('RSI', 'ä¸­ç«‹', f"RSI={latest['RSI']:.1f}", 'neutral'))
    
    # ç§»å‹•å¹³å‡
    if latest['Close'] > latest['SMA_20'] > latest['SMA_50']:
        signals.append(('ç§»å‹•å¹³å‡', 'è²·ã„', 'ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰', 'buy'))
    elif latest['Close'] < latest['SMA_20'] < latest['SMA_50']:
        signals.append(('ç§»å‹•å¹³å‡', 'å£²ã‚Š', 'ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰', 'sell'))
    else:
        signals.append(('ç§»å‹•å¹³å‡', 'ä¸­ç«‹', 'ãƒ¬ãƒ³ã‚¸ç›¸å ´', 'neutral'))
    
    # MACD
    if latest['MACD'] > latest['MACD_signal']:
        signals.append(('MACD', 'è²·ã„', 'ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¯ãƒ­ã‚¹', 'buy'))
    else:
        signals.append(('MACD', 'å£²ã‚Š', 'ãƒ‡ãƒƒãƒ‰ã‚¯ãƒ­ã‚¹', 'sell'))
    
    # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
    if latest['Close'] < latest['BB_lower']:
        signals.append(('BB', 'è²·ã„', 'ä¸‹ãƒãƒ³ãƒ‰å‰²ã‚Œ', 'buy'))
    elif latest['Close'] > latest['BB_upper']:
        signals.append(('BB', 'å£²ã‚Š', 'ä¸Šãƒãƒ³ãƒ‰çªç ´', 'sell'))
    else:
        signals.append(('BB', 'ä¸­ç«‹', 'ãƒãƒ³ãƒ‰å†…', 'neutral'))
    
    return signals


def create_chart(data: pd.DataFrame, arima_pred=None, arima_ci=None, ml_pred=None, lstm_pred=None,
                 lightgbm_pred=None, garch_pred=None, garch_upper=None, garch_lower=None, forecast_days=30):
    """Plotlyãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ"""
    go, make_subplots = load_plotly()
    fig = make_subplots(
        rows=4, cols=1,
        shared_xaxes=True,
        vertical_spacing=0.05,
        row_heights=[0.5, 0.15, 0.15, 0.2],
        subplot_titles=('æ ªä¾¡', 'RSI', 'MACD', 'å‡ºæ¥é«˜')
    )
    
    # æ ªä¾¡ãƒãƒ£ãƒ¼ãƒˆ
    fig.add_trace(go.Candlestick(
        x=data.index,
        open=data['Open'],
        high=data['High'],
        low=data['Low'],
        close=data['Close'],
        name='æ ªä¾¡'
    ), row=1, col=1)
    
    fig.add_trace(go.Scatter(x=data.index, y=data['SMA_20'], name='SMA20',
                            line=dict(color='orange', width=1)), row=1, col=1)
    fig.add_trace(go.Scatter(x=data.index, y=data['SMA_50'], name='SMA50',
                            line=dict(color='blue', width=1)), row=1, col=1)
    
    # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
    fig.add_trace(go.Scatter(x=data.index, y=data['BB_upper'], name='BB Upper',
                            line=dict(color='gray', width=1, dash='dash')), row=1, col=1)
    fig.add_trace(go.Scatter(x=data.index, y=data['BB_lower'], name='BB Lower',
                            line=dict(color='gray', width=1, dash='dash'),
                            fill='tonexty', fillcolor='rgba(128,128,128,0.1)'), row=1, col=1)
    
    # äºˆæ¸¬
    if arima_pred is not None:
        forecast_dates = pd.date_range(start=data.index[-1] + timedelta(days=1),
                                       periods=forecast_days, freq='B')
        fig.add_trace(go.Scatter(x=forecast_dates, y=arima_pred, name='ARIMAäºˆæ¸¬',
                                line=dict(color='red', dash='dash')), row=1, col=1)
        if arima_ci is not None:
            fig.add_trace(go.Scatter(x=forecast_dates, y=arima_ci['upper'],
                                    line=dict(color='red', width=0), showlegend=False), row=1, col=1)
            fig.add_trace(go.Scatter(x=forecast_dates, y=arima_ci['lower'],
                                    line=dict(color='red', width=0), fill='tonexty',
                                    fillcolor='rgba(255,0,0,0.1)', name='ARIMA 95%CI'), row=1, col=1)
    
    if ml_pred is not None:
        forecast_dates = pd.date_range(start=data.index[-1] + timedelta(days=1),
                                       periods=forecast_days, freq='B')
        fig.add_trace(go.Scatter(x=forecast_dates, y=ml_pred, name='MLäºˆæ¸¬',
                                line=dict(color='green', dash='dash')), row=1, col=1)
    
    if lstm_pred is not None:
        forecast_dates = pd.date_range(start=data.index[-1] + timedelta(days=1),
                                       periods=forecast_days, freq='B')
        fig.add_trace(go.Scatter(x=forecast_dates, y=lstm_pred, name='LSTMäºˆæ¸¬',
                                line=dict(color='purple', dash='dash', width=2)), row=1, col=1)
    
    if lightgbm_pred is not None:
        forecast_dates = pd.date_range(start=data.index[-1] + timedelta(days=1),
                                       periods=forecast_days, freq='B')
        fig.add_trace(go.Scatter(x=forecast_dates, y=lightgbm_pred, name='LightGBMäºˆæ¸¬',
                                line=dict(color='orange', dash='dash', width=2)), row=1, col=1)
    
    if garch_pred is not None:
        forecast_dates = pd.date_range(start=data.index[-1] + timedelta(days=1),
                                       periods=forecast_days, freq='B')
        fig.add_trace(go.Scatter(x=forecast_dates, y=garch_pred, name='GARCHäºˆæ¸¬',
                                line=dict(color='cyan', dash='dash', width=2)), row=1, col=1)
        # ä¿¡é ¼åŒºé–“ã¯å‰Šé™¤ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«ãŒå´©ã‚Œã‚‹ãŸã‚ï¼‰
    
    # RSI
    fig.add_trace(go.Scatter(x=data.index, y=data['RSI'], name='RSI',
                            line=dict(color='purple')), row=2, col=1)
    fig.add_hline(y=70, line_dash="dash", line_color="red", row=2, col=1)
    fig.add_hline(y=30, line_dash="dash", line_color="green", row=2, col=1)
    
    # MACD
    fig.add_trace(go.Scatter(x=data.index, y=data['MACD'], name='MACD',
                            line=dict(color='blue')), row=3, col=1)
    fig.add_trace(go.Scatter(x=data.index, y=data['MACD_signal'], name='Signal',
                            line=dict(color='orange')), row=3, col=1)
    
    # å‡ºæ¥é«˜
    colors = ['green' if data['Close'].iloc[i] >= data['Open'].iloc[i] else 'red'
              for i in range(len(data))]
    fig.add_trace(go.Bar(x=data.index, y=data['Volume'], name='å‡ºæ¥é«˜',
                        marker_color=colors), row=4, col=1)
    
    fig.update_layout(
        height=900,
        showlegend=True,
        xaxis_rangeslider_visible=False
    )
    
    return fig


# ================== ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª ==================

st.title("ğŸ“ˆ æ ªä¾¡åˆ†æãƒ„ãƒ¼ãƒ«")
st.markdown("""
ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æ + çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ ªä¾¡åˆ†æ  
âš ï¸ **æ³¨æ„**: äºˆæ¸¬ã¯å‚è€ƒå€¤ã§ã™ã€‚æ ªä¾¡ã®æ­£ç¢ºãªäºˆæ¸¬ã¯åŸç†çš„ã«å›°é›£ã§ã™ã€‚
""")

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šï¼ˆé…å»¶ãƒ­ãƒ¼ãƒ‰ï¼‰
@st.cache_resource
def load_database():
    try:
        from database import get_db
        return get_db(), True
    except ImportError:
        return None, False

db, db_available = load_database()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
st.sidebar.header("âš™ï¸ è¨­å®š")

# ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆã‹ã‚‰é¸æŠï¼ˆDBãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
if db_available:
    watchlist = db.get_watchlist()
    if watchlist:
        watchlist_options = ["ç›´æ¥å…¥åŠ›"] + [f"{w['ticker']} - {w['name'] or ''}" for w in watchlist]
        selected_from_watchlist = st.sidebar.selectbox("ğŸ“‹ ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆã‹ã‚‰é¸æŠ", watchlist_options)
        
        if selected_from_watchlist != "ç›´æ¥å…¥åŠ›":
            default_ticker = selected_from_watchlist.split(" - ")[0]
        else:
            default_ticker = st.session_state.get('selected_ticker', 'AAPL')
    else:
        default_ticker = st.session_state.get('selected_ticker', 'AAPL')
        st.sidebar.caption("ğŸ“‹ [ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆã«éŠ˜æŸ„ã‚’è¿½åŠ ](/02_watchlist)")
else:
    default_ticker = 'AAPL'

ticker = st.sidebar.text_input(
    "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰",
    value=default_ticker,
    help="ä¾‹: AAPL, GOOGL, 7203.T (ãƒˆãƒ¨ã‚¿)"
)

period = st.sidebar.selectbox(
    "ãƒ‡ãƒ¼ã‚¿æœŸé–“",
    options=["1y", "2y", "5y"],
    index=1
)

forecast_days = st.sidebar.slider(
    "äºˆæ¸¬æ—¥æ•°",
    min_value=7,
    max_value=90,
    value=30
)

st.sidebar.subheader("ğŸ“Š äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«")
run_arima = st.sidebar.checkbox("ARIMA (æ™‚ç³»åˆ—)", value=True)
run_ml = st.sidebar.checkbox("Random Forest", value=False)

# LightGBM ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆè»½é‡ãƒã‚§ãƒƒã‚¯ï¼‰
lightgbm_available = check_lightgbm_available()
if lightgbm_available:
    run_lightgbm = st.sidebar.checkbox("âš¡ LightGBM (æ¨å¥¨)", value=True)
else:
    run_lightgbm = False
    st.sidebar.warning("âš ï¸ LightGBMæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")

# GARCH ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆè»½é‡ãƒã‚§ãƒƒã‚¯ï¼‰
arch_available = check_garch_available()
if arch_available:
    run_garch = st.sidebar.checkbox("ğŸ“‰ GARCH (ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£)", value=True)
else:
    run_garch = False
    st.sidebar.warning("âš ï¸ archæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")

# LSTM (GPUå¯¾å¿œ) ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆè»½é‡ãƒã‚§ãƒƒã‚¯ï¼‰
pytorch_available = check_pytorch_available()
if pytorch_available:
    run_lstm = st.sidebar.checkbox("ğŸ§  LSTM (æ·±å±¤å­¦ç¿’)", value=False)
    if run_lstm:
        # LSTMã‚’ä½¿ã†å ´åˆã®ã¿PyTorchã‚’ãƒ­ãƒ¼ãƒ‰
        torch, StockLSTMPredictor, get_device, _ = load_pytorch()
        device = get_device()
        if torch.cuda.is_available():
            st.sidebar.success(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")
        else:
            st.sidebar.info("ğŸ’» CPU ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
        lstm_epochs = st.sidebar.slider("LSTMã‚¨ãƒãƒƒã‚¯æ•°", 50, 200, 100)
else:
    run_lstm = False

# åˆ†æå®Ÿè¡Œãƒœã‚¿ãƒ³
if st.sidebar.button("ğŸ” åˆ†æå®Ÿè¡Œ", type="primary"):
    with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
        data, data_source = fetch_stock_data(ticker, period)
        data = add_indicators(data)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®è¡¨ç¤º
    source_icons = {
        "cache": "âš¡ ã‚­ãƒ£ãƒƒã‚·ãƒ¥",
        "api": "ğŸŒ API",
        "stale_cache": "ğŸ“¦ å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥"
    }
    st.caption(f"ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {source_icons.get(data_source, data_source)}")
    
    # ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆã«è¿½åŠ ãƒœã‚¿ãƒ³
    if db_available:
        # ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        watchlist_tickers = [w['ticker'] for w in db.get_watchlist()]
        if ticker.upper() not in watchlist_tickers:
            if st.button(f"ğŸ“‹ {ticker.upper()} ã‚’ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆã«è¿½åŠ "):
                db.add_to_watchlist(ticker)
                st.success(f"âœ… {ticker.upper()} ã‚’ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆã«è¿½åŠ ã—ã¾ã—ãŸ")
                st.rerun()
        else:
            st.caption(f"âœ… {ticker.upper()} ã¯ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆã«ç™»éŒ²æ¸ˆã¿")
    
    # åŸºæœ¬æƒ…å ±
    col1, col2, col3, col4 = st.columns(4)
    latest = data.iloc[-1]
    prev = data.iloc[-2]
    change = (latest['Close'] - prev['Close']) / prev['Close'] * 100
    
    col1.metric("æœ€æ–°æ ªä¾¡", f"{latest['Close']:.2f}", f"{change:+.2f}%")
    col2.metric("é«˜å€¤", f"{latest['High']:.2f}")
    col3.metric("å®‰å€¤", f"{latest['Low']:.2f}")
    col4.metric("å‡ºæ¥é«˜", f"{latest['Volume']:,.0f}")
    
    # äºˆæ¸¬å®Ÿè¡Œ
    arima_pred, arima_ci, ml_pred, lstm_pred = None, None, None, None
    lightgbm_pred, garch_pred, garch_upper, garch_lower = None, None, None, None
    
    if run_arima:
        with st.spinner("ARIMAäºˆæ¸¬ä¸­..."):
            arima_pred, arima_ci, order = predict_arima(data, forecast_days)
            st.success(f"âœ… ARIMA{order} äºˆæ¸¬å®Œäº†")
    
    if run_ml:
        with st.spinner("Random Forestäºˆæ¸¬ä¸­..."):
            ml_pred, score = predict_ml(data, forecast_days)
            st.success(f"âœ… Random Forestäºˆæ¸¬å®Œäº† (RÂ²={score:.4f})")
    
    if run_lightgbm and lightgbm_available:
        with st.spinner("âš¡ LightGBMäºˆæ¸¬ä¸­..."):
            try:
                StockLightGBMPredictor, _ = load_lightgbm()
                lgb_predictor = StockLightGBMPredictor(n_estimators=500, learning_rate=0.05)
                result = lgb_predictor.train(data, target_days=1, verbose=False)
                lightgbm_pred = lgb_predictor.predict(data, forecast_days=forecast_days)
                st.success(f"âœ… LightGBMäºˆæ¸¬å®Œäº† (æ–¹å‘ç²¾åº¦={result['direction_accuracy']:.1f}%)")
            except Exception as e:
                st.error(f"âŒ LightGBMäºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
    
    if run_garch and arch_available:
        with st.spinner("ğŸ“‰ GARCHäºˆæ¸¬ä¸­..."):
            try:
                StockGARCHPredictor, _ = load_garch()
                garch_predictor = StockGARCHPredictor(p=1, q=1)
                garch_predictor.train(data, verbose=False)
                price_range = garch_predictor.predict_price_range(data, forecast_days=forecast_days)
                garch_pred = price_range['Price_Mean'].values
                garch_upper = price_range['Price_Upper'].values
                garch_lower = price_range['Price_Lower'].values
                st.success(f"âœ… GARCHäºˆæ¸¬å®Œäº† (ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£äºˆæ¸¬)")
            except Exception as e:
                st.error(f"âŒ GARCHäºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
    
    if run_lstm and pytorch_available:
        with st.spinner("ğŸ§  LSTMäºˆæ¸¬ä¸­..."):
            try:
                torch, StockLSTMPredictor, get_device, _ = load_pytorch()
                predictor = StockLSTMPredictor(sequence_length=30, hidden_size=64)
                predictor.train(data['Close'].values, epochs=lstm_epochs, verbose=False)
                lstm_pred = predictor.predict(data['Close'].values, forecast_days=forecast_days)
                device_name = "GPU" if torch.cuda.is_available() else "CPU"
                st.success(f"âœ… LSTMäºˆæ¸¬å®Œäº† ({device_name}ä½¿ç”¨)")
            except Exception as e:
                st.error(f"âŒ LSTMäºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ã‚·ã‚°ãƒŠãƒ«è¡¨ç¤º
    st.subheader("ğŸ“Š å£²è²·ã‚·ã‚°ãƒŠãƒ«")
    signals = get_signals(data)
    
    cols = st.columns(4)
    for i, (indicator, signal, reason, signal_type) in enumerate(signals):
        with cols[i]:
            if signal_type == 'buy':
                st.markdown(f"""
                <div class="signal-buy">
                    <strong>ğŸŸ¢ {indicator}</strong><br>
                    {signal}: {reason}
                </div>
                """, unsafe_allow_html=True)
            elif signal_type == 'sell':
                st.markdown(f"""
                <div class="signal-sell">
                    <strong>ğŸ”´ {indicator}</strong><br>
                    {signal}: {reason}
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div class="signal-neutral">
                    <strong>âšª {indicator}</strong><br>
                    {signal}: {reason}
                </div>
                """, unsafe_allow_html=True)
    
    # ç·åˆåˆ¤æ–­
    buy_count = sum(1 for _, s, _, _ in signals if s == 'è²·ã„')
    sell_count = sum(1 for _, s, _, _ in signals if s == 'å£²ã‚Š')
    
    st.subheader("ğŸ¯ ç·åˆåˆ¤æ–­")
    if buy_count > sell_count:
        st.success(f"ğŸ“ˆ **è²·ã„å„ªå‹¢** (è²·ã„{buy_count} / å£²ã‚Š{sell_count})")
    elif sell_count > buy_count:
        st.error(f"ğŸ“‰ **å£²ã‚Šå„ªå‹¢** (è²·ã„{buy_count} / å£²ã‚Š{sell_count})")
    else:
        st.warning(f"â¡ï¸ **ä¸­ç«‹** (è²·ã„{buy_count} / å£²ã‚Š{sell_count})")
    
    # äºˆæ¸¬çµæœ
    has_predictions = any([arima_pred is not None, ml_pred is not None, 
                          lstm_pred is not None, lightgbm_pred is not None,
                          garch_pred is not None])
    
    if has_predictions:
        st.subheader("ğŸ”® äºˆæ¸¬çµæœ")
        
        # äºˆæ¸¬ã‚«ãƒ¼ãƒ‰è¡¨ç¤º
        pred_items = []
        if arima_pred is not None:
            pred_items.append(("ARIMA", arima_pred.iloc[-1]))
        if lightgbm_pred is not None:
            pred_items.append(("âš¡ LightGBM", lightgbm_pred[-1]))
        if garch_pred is not None:
            pred_items.append(("ğŸ“‰ GARCH", garch_pred[-1]))
        if ml_pred is not None:
            pred_items.append(("RF", ml_pred[-1]))
        if lstm_pred is not None:
            pred_items.append(("ğŸ§  LSTM", lstm_pred[-1]))
        
        pred_cols = st.columns(len(pred_items))
        for i, (name, future_price) in enumerate(pred_items):
            change = (future_price - latest['Close']) / latest['Close'] * 100
            with pred_cols[i]:
                st.metric(
                    f"{name} ({forecast_days}æ—¥å¾Œ)",
                    f"{future_price:.2f}",
                    f"{change:+.2f}%"
                )
        
        # GARCHã®ä¾¡æ ¼ãƒ¬ãƒ³ã‚¸è¡¨ç¤º
        if garch_pred is not None and garch_upper is not None:
            st.info(f"ğŸ“‰ GARCH 95%ä¿¡é ¼åŒºé–“: {garch_lower[-1]:.2f} ï½ {garch_upper[-1]:.2f}")
    
    # ãƒãƒ£ãƒ¼ãƒˆ
    st.subheader("ğŸ“ˆ ãƒãƒ£ãƒ¼ãƒˆ")
    fig = create_chart(data, arima_pred, arima_ci, ml_pred, lstm_pred, 
                      lightgbm_pred, garch_pred, garch_upper, garch_lower, forecast_days)
    st.plotly_chart(fig, use_container_width=True)
    
    # äºˆæ¸¬ã®é™ç•Œã«ã¤ã„ã¦ã®èª¬æ˜
    with st.expander("âš ï¸ äºˆæ¸¬ã®é™ç•Œã«ã¤ã„ã¦ï¼ˆé‡è¦ï¼‰"):
        st.markdown("""
        ### æ ªä¾¡äºˆæ¸¬ã®ç¾å®Ÿ
        
        **ãªãœäºˆæ¸¬ã¯å¤–ã‚Œã‚‹ã®ã‹ï¼Ÿ**
        
        1. **åŠ¹ç‡çš„å¸‚å ´ä»®èª¬**: æ ªä¾¡ã¯æ—¢ã«å…¨ã¦ã®æƒ…å ±ã‚’ç¹”ã‚Šè¾¼ã‚“ã§ã„ã‚‹ãŸã‚ã€
           éå»ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å°†æ¥ã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã¯ç†è«–ä¸Šä¸å¯èƒ½ã§ã™ã€‚
        
        2. **ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯**: çŸ­æœŸçš„ãªæ ªä¾¡å¤‰å‹•ã¯ã»ã¼ãƒ©ãƒ³ãƒ€ãƒ ã§ã‚ã‚Šã€
           çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã§æ‰ãˆã‚‹ã“ã¨ãŒéå¸¸ã«å›°é›£ã§ã™ã€‚
        
        3. **å¤–éƒ¨è¦å› **: æ±ºç®—ç™ºè¡¨ã€çµŒæ¸ˆæŒ‡æ¨™ã€åœ°æ”¿å­¦ãƒªã‚¹ã‚¯ã€çªç™ºçš„ãƒ‹ãƒ¥ãƒ¼ã‚¹ãªã©ã€
           éå»ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œãªã„è¦å› ãŒæ ªä¾¡ã‚’å¤§ããå‹•ã‹ã—ã¾ã™ã€‚
        
        **ã“ã®ãƒ„ãƒ¼ãƒ«ã®æ­£ã—ã„ä½¿ã„æ–¹**
        
        - âŒ äºˆæ¸¬å€¤ã‚’ä¿¡ã˜ã¦å£²è²·ã™ã‚‹
        - âœ… ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã®ç¢ºèª
        - âœ… ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå¤‰å‹•ãƒªã‚¹ã‚¯ï¼‰ã®æŠŠæ¡
        - âœ… ãƒˆãƒ¬ãƒ³ãƒ‰ã®æ–¹å‘æ€§ã®å‚è€ƒ
        - âœ… è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®ä¸€è‡´åº¦ã‚’è¦‹ã‚‹
        
        **å­¦è¡“ç ”ç©¶ã®çµè«–**
        
        > ã€ŒçŸ­æœŸçš„ãªæ ªä¾¡äºˆæ¸¬ã¯ã€ã‚³ã‚¤ãƒ³ã‚’æŠ•ã’ã‚‹ã®ã¨åŒç¨‹åº¦ã®ç²¾åº¦ã—ã‹ãªã„ã€
        > - å¤šãã®é‡‘èçµŒæ¸ˆå­¦è€…ã®è¦‹è§£
        """)
    
    # æ³¨æ„æ›¸ã
    st.error("âš ï¸ **é‡è¦**: ã“ã®äºˆæ¸¬ã¯å‚è€ƒæƒ…å ±ã§ã™ã€‚äºˆæ¸¬ç²¾åº¦ã¯ä¿è¨¼ã•ã‚Œã¾ã›ã‚“ã€‚æŠ•è³‡åˆ¤æ–­ã¯è‡ªå·±è²¬ä»»ã§è¡Œã£ã¦ãã ã•ã„ã€‚")

else:
    st.info("ğŸ‘ˆ å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§éŠ˜æŸ„ã‚’è¨­å®šã—ã€ã€Œåˆ†æå®Ÿè¡Œã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„")
    
    # ã‚µãƒ³ãƒ—ãƒ«éŠ˜æŸ„
    st.subheader("ğŸ“Œ äººæ°—éŠ˜æŸ„")
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **ğŸ‡ºğŸ‡¸ ç±³å›½æ ª**
        - AAPL (Apple)
        - GOOGL (Google)
        - MSFT (Microsoft)
        - AMZN (Amazon)
        - TSLA (Tesla)
        - NVDA (NVIDIA)
        """)
    
    with col2:
        st.markdown("""
        **ğŸ‡¯ğŸ‡µ æ—¥æœ¬æ ª**
        - 7203.T (ãƒˆãƒ¨ã‚¿)
        - 9984.T (ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯G)
        - 6758.T (ã‚½ãƒ‹ãƒ¼)
        - 6861.T (ã‚­ãƒ¼ã‚¨ãƒ³ã‚¹)
        - 9432.T (NTT)
        - 8306.T (ä¸‰è±UFJ)
        """)
