"""
äºˆæ¸¬ç²¾åº¦ã®æ¤œè¨¼ãƒšãƒ¼ã‚¸
==================
éŽåŽ»ã®äºˆæ¸¬ã¨å®Ÿç¸¾ã‚’æ¯”è¼ƒã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’ç¢ºèªã™ã‚‹
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

try:
    import yfinance as yf
    YFINANCE_AVAILABLE = True
except ImportError:
    YFINANCE_AVAILABLE = False

from statsmodels.tsa.arima.model import ARIMA
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler

st.set_page_config(
    page_title="ðŸ“Š äºˆæ¸¬ç²¾åº¦æ¤œè¨¼",
    page_icon="ðŸ“Š",
    layout="wide"
)

st.title("ðŸ“Š äºˆæ¸¬ç²¾åº¦ã®æ¤œè¨¼")
st.markdown("éŽåŽ»ã®äºˆæ¸¬ã¨å®Ÿéš›ã®çµæžœã‚’æ¯”è¼ƒã—ã¦ã€äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’ç¢ºèªã—ã¾ã™ã€‚")


@st.cache_data(ttl=3600)
def fetch_stock_data(ticker: str, period: str) -> pd.DataFrame:
    """æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    if YFINANCE_AVAILABLE:
        try:
            import ssl
            ssl._create_default_https_context = ssl._create_unverified_context
            stock = yf.Ticker(ticker)
            data = stock.history(period=period)
            if len(data) > 0:
                return data
        except:
            pass
    
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
    np.random.seed(hash(ticker) % 100)
    days = 500
    dates = pd.date_range(end=datetime.now(), periods=days, freq='B')
    returns = np.random.normal(0.0005, 0.02, days)
    price = 100 * np.exp(np.cumsum(returns))
    
    return pd.DataFrame({
        'Open': price * (1 + np.random.uniform(-0.01, 0.01, days)),
        'High': price * (1 + np.random.uniform(0, 0.02, days)),
        'Low': price * (1 - np.random.uniform(0, 0.02, days)),
        'Close': price,
        'Volume': np.random.randint(1000000, 10000000, days)
    }, index=dates)


def add_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã‚’è¿½åŠ """
    df = df.copy()
    df['SMA_5'] = df['Close'].rolling(window=5).mean()
    df['SMA_20'] = df['Close'].rolling(window=20).mean()
    
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))
    
    exp1 = df['Close'].ewm(span=12, adjust=False).mean()
    exp2 = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = exp1 - exp2
    
    df['Return'] = df['Close'].pct_change()
    df['Return_5d'] = df['Close'].pct_change(5)
    df['Volume_SMA'] = df['Volume'].rolling(window=20).mean()
    df['Volume_ratio'] = df['Volume'] / df['Volume_SMA']
    
    return df.dropna()


def backtest_arima(data: pd.DataFrame, test_days: int = 30):
    """ARIMAãƒ¢ãƒ‡ãƒ«ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ"""
    results = []
    
    for i in range(test_days, 0, -1):
        train_data = data['Close'].iloc[:-i]
        actual = data['Close'].iloc[-i]
        actual_date = data.index[-i]
        
        try:
            model = ARIMA(train_data, order=(1, 1, 1))
            result = model.fit()
            pred = result.forecast(steps=1).iloc[0]
            
            results.append({
                'Date': actual_date,
                'Actual': actual,
                'Predicted': pred,
                'Error': actual - pred,
                'Error_Pct': (actual - pred) / actual * 100
            })
        except:
            continue
    
    return pd.DataFrame(results)


def backtest_ml(data: pd.DataFrame, test_days: int = 30):
    """æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ"""
    df_ml = data.copy()
    for i in range(1, 6):
        df_ml[f'Close_lag{i}'] = df_ml['Close'].shift(i)
    df_ml = df_ml.dropna()
    
    features = ['SMA_5', 'SMA_20', 'RSI', 'MACD', 'Volume_ratio', 'Return_5d'] + \
               [f'Close_lag{i}' for i in range(1, 6)]
    
    results = []
    
    for i in range(test_days, 0, -1):
        train_idx = len(df_ml) - i
        if train_idx < 100:
            continue
            
        X_train = df_ml[features].iloc[:train_idx].values
        y_train = df_ml['Close'].iloc[:train_idx].values
        
        X_test = df_ml[features].iloc[train_idx:train_idx+1].values
        actual = df_ml['Close'].iloc[train_idx]
        actual_date = df_ml.index[train_idx]
        
        try:
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            model = RandomForestRegressor(n_estimators=50, random_state=42)
            model.fit(X_train_scaled, y_train)
            pred = model.predict(X_test_scaled)[0]
            
            results.append({
                'Date': actual_date,
                'Actual': actual,
                'Predicted': pred,
                'Error': actual - pred,
                'Error_Pct': (actual - pred) / actual * 100
            })
        except:
            continue
    
    return pd.DataFrame(results)


def calculate_metrics(results_df: pd.DataFrame) -> dict:
    """ç²¾åº¦æŒ‡æ¨™ã‚’è¨ˆç®—"""
    if len(results_df) == 0:
        return {}
    
    mae = np.mean(np.abs(results_df['Error']))
    rmse = np.sqrt(np.mean(results_df['Error'] ** 2))
    mape = np.mean(np.abs(results_df['Error_Pct']))
    
    # æ–¹å‘æ€§ã®çš„ä¸­çŽ‡
    results_df['Actual_Direction'] = (results_df['Actual'].diff() > 0).astype(int)
    results_df['Pred_Direction'] = (results_df['Predicted'].diff() > 0).astype(int)
    direction_accuracy = (results_df['Actual_Direction'] == results_df['Pred_Direction']).mean() * 100
    
    return {
        'MAE': mae,
        'RMSE': rmse,
        'MAPE': mape,
        'Direction_Accuracy': direction_accuracy
    }


def create_backtest_chart(arima_results: pd.DataFrame, ml_results: pd.DataFrame):
    """ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæžœã®ãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ"""
    fig = make_subplots(
        rows=3, cols=1,
        shared_xaxes=True,
        vertical_spacing=0.08,
        row_heights=[0.5, 0.25, 0.25],
        subplot_titles=('äºˆæ¸¬ vs å®Ÿç¸¾', 'äºˆæ¸¬èª¤å·® (%)', 'ç´¯ç©èª¤å·®')
    )
    
    # å®Ÿç¸¾
    if len(arima_results) > 0:
        fig.add_trace(go.Scatter(
            x=arima_results['Date'], y=arima_results['Actual'],
            name='å®Ÿç¸¾', line=dict(color='blue', width=2)
        ), row=1, col=1)
        
        fig.add_trace(go.Scatter(
            x=arima_results['Date'], y=arima_results['Predicted'],
            name='ARIMAäºˆæ¸¬', line=dict(color='red', dash='dash')
        ), row=1, col=1)
        
        fig.add_trace(go.Bar(
            x=arima_results['Date'], y=arima_results['Error_Pct'],
            name='ARIMAèª¤å·®', marker_color='red', opacity=0.5
        ), row=2, col=1)
        
        fig.add_trace(go.Scatter(
            x=arima_results['Date'], y=arima_results['Error'].cumsum(),
            name='ARIMAç´¯ç©èª¤å·®', line=dict(color='red')
        ), row=3, col=1)
    
    if len(ml_results) > 0:
        fig.add_trace(go.Scatter(
            x=ml_results['Date'], y=ml_results['Predicted'],
            name='MLäºˆæ¸¬', line=dict(color='green', dash='dash')
        ), row=1, col=1)
        
        fig.add_trace(go.Bar(
            x=ml_results['Date'], y=ml_results['Error_Pct'],
            name='MLèª¤å·®', marker_color='green', opacity=0.5
        ), row=2, col=1)
        
        fig.add_trace(go.Scatter(
            x=ml_results['Date'], y=ml_results['Error'].cumsum(),
            name='MLç´¯ç©èª¤å·®', line=dict(color='green')
        ), row=3, col=1)
    
    fig.update_layout(height=800, showlegend=True)
    fig.add_hline(y=0, line_dash="dash", line_color="gray", row=2, col=1)
    fig.add_hline(y=0, line_dash="dash", line_color="gray", row=3, col=1)
    
    return fig


# ã‚µã‚¤ãƒ‰ãƒãƒ¼
st.sidebar.header("âš™ï¸ è¨­å®š")

ticker = st.sidebar.text_input(
    "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰",
    value="AAPL",
    help="ä¾‹: AAPL, GOOGL, 7203.T"
)

test_days = st.sidebar.slider(
    "æ¤œè¨¼æœŸé–“ï¼ˆæ—¥æ•°ï¼‰",
    min_value=10,
    max_value=60,
    value=30
)

run_arima = st.sidebar.checkbox("ARIMA", value=True)
run_ml = st.sidebar.checkbox("æ©Ÿæ¢°å­¦ç¿’", value=True)

# æ¤œè¨¼å®Ÿè¡Œ
if st.sidebar.button("ðŸ” æ¤œè¨¼å®Ÿè¡Œ", type="primary"):
    with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
        data = fetch_stock_data(ticker, "2y")
        data = add_indicators(data)
    
    st.success(f"âœ… {ticker} ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸï¼ˆ{len(data)}æ—¥åˆ†ï¼‰")
    
    arima_results = pd.DataFrame()
    ml_results = pd.DataFrame()
    
    # ARIMA ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
    if run_arima:
        with st.spinner("ARIMAãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­..."):
            arima_results = backtest_arima(data, test_days)
        
        if len(arima_results) > 0:
            arima_metrics = calculate_metrics(arima_results)
            
            st.subheader("ðŸ“ˆ ARIMA ãƒ¢ãƒ‡ãƒ«ç²¾åº¦")
            cols = st.columns(4)
            cols[0].metric("MAE", f"{arima_metrics['MAE']:.2f}")
            cols[1].metric("RMSE", f"{arima_metrics['RMSE']:.2f}")
            cols[2].metric("MAPE", f"{arima_metrics['MAPE']:.2f}%")
            cols[3].metric("æ–¹å‘çš„ä¸­çŽ‡", f"{arima_metrics['Direction_Accuracy']:.1f}%")
    
    # ML ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
    if run_ml:
        with st.spinner("æ©Ÿæ¢°å­¦ç¿’ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­..."):
            ml_results = backtest_ml(data, test_days)
        
        if len(ml_results) > 0:
            ml_metrics = calculate_metrics(ml_results)
            
            st.subheader("ðŸ¤– æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ç²¾åº¦")
            cols = st.columns(4)
            cols[0].metric("MAE", f"{ml_metrics['MAE']:.2f}")
            cols[1].metric("RMSE", f"{ml_metrics['RMSE']:.2f}")
            cols[2].metric("MAPE", f"{ml_metrics['MAPE']:.2f}%")
            cols[3].metric("æ–¹å‘çš„ä¸­çŽ‡", f"{ml_metrics['Direction_Accuracy']:.1f}%")
    
    # ãƒãƒ£ãƒ¼ãƒˆ
    st.subheader("ðŸ“Š ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæžœ")
    fig = create_backtest_chart(arima_results, ml_results)
    st.plotly_chart(fig, use_container_width=True)
    
    # è©³ç´°ãƒ‡ãƒ¼ã‚¿
    with st.expander("ðŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º"):
        tab1, tab2 = st.tabs(["ARIMA", "æ©Ÿæ¢°å­¦ç¿’"])
        
        with tab1:
            if len(arima_results) > 0:
                st.dataframe(arima_results.round(2), use_container_width=True)
        
        with tab2:
            if len(ml_results) > 0:
                st.dataframe(ml_results.round(2), use_container_width=True)
    
    # è©•ä¾¡ã‚µãƒžãƒªãƒ¼
    st.subheader("ðŸ“ è©•ä¾¡ã‚µãƒžãƒªãƒ¼")
    
    if len(arima_results) > 0 and len(ml_results) > 0:
        arima_mape = calculate_metrics(arima_results)['MAPE']
        ml_mape = calculate_metrics(ml_results)['MAPE']
        
        if arima_mape < ml_mape:
            st.info(f"ðŸ† **ARIMA** ã®æ–¹ãŒç²¾åº¦ãŒé«˜ã„ã§ã™ï¼ˆMAPE: {arima_mape:.2f}% vs {ml_mape:.2f}%ï¼‰")
        else:
            st.info(f"ðŸ† **æ©Ÿæ¢°å­¦ç¿’** ã®æ–¹ãŒç²¾åº¦ãŒé«˜ã„ã§ã™ï¼ˆMAPE: {ml_mape:.2f}% vs {arima_mape:.2f}%ï¼‰")
    
    st.markdown("""
    **æŒ‡æ¨™ã®èª¬æ˜Ž:**
    - **MAE (Mean Absolute Error)**: å¹³å‡çµ¶å¯¾èª¤å·®ã€‚å°ã•ã„ã»ã©è‰¯ã„ã€‚
    - **RMSE (Root Mean Squared Error)**: äºŒä¹—å¹³å‡å¹³æ–¹æ ¹èª¤å·®ã€‚å¤–ã‚Œå€¤ã«æ•æ„Ÿã€‚
    - **MAPE (Mean Absolute Percentage Error)**: å¹³å‡çµ¶å¯¾ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆèª¤å·®ã€‚10%ä»¥ä¸‹ãŒç›®å®‰ã€‚
    - **æ–¹å‘çš„ä¸­çŽ‡**: ä¸Šæ˜‡/ä¸‹é™ã‚’æ­£ã—ãäºˆæ¸¬ã—ãŸå‰²åˆã€‚50%ä»¥ä¸Šãªã‚‰æ„å‘³ãŒã‚ã‚‹ã€‚
    """)

else:
    st.info("ðŸ‘ˆ å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§éŠ˜æŸ„ã‚’è¨­å®šã—ã€ã€Œæ¤œè¨¼å®Ÿè¡Œã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„")
    
    st.markdown("""
    ### ã“ã®ãƒšãƒ¼ã‚¸ã§ã§ãã‚‹ã“ã¨
    
    1. **ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ**: éŽåŽ»ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ã€äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’æ¤œè¨¼
    2. **ç²¾åº¦æ¯”è¼ƒ**: ARIMAã¨æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æ¯”è¼ƒ
    3. **æ–¹å‘æ€§åˆ†æž**: ä¾¡æ ¼ã®ä¸Šæ˜‡/ä¸‹é™ã‚’æ­£ã—ãäºˆæ¸¬ã§ãã¦ã„ã‚‹ã‹ç¢ºèª
    
    ### ä½¿ã„æ–¹
    
    1. éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ›
    2. æ¤œè¨¼æœŸé–“ã‚’è¨­å®šï¼ˆéŽåŽ»ä½•æ—¥åˆ†ã‚’æ¤œè¨¼ã™ã‚‹ã‹ï¼‰
    3. æ¤œè¨¼ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠž
    4. ã€Œæ¤œè¨¼å®Ÿè¡Œã€ã‚’ã‚¯ãƒªãƒƒã‚¯
    """)
